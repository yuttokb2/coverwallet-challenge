#!/bin/bash
# Script para probar el pipeline completo de ML

set -e

echo "üöÄ Iniciando prueba del pipeline ML de CoverWallet..."

# Variables
BASE_DIR=$(pwd)
DATA_DIR="$BASE_DIR/data"
SRC_DIR="$BASE_DIR/src"
MODEL_DIR="$BASE_DIR/model"

echo "üìÅ Verificando archivos necesarios..."

# Verificar archivos de entrada
REQUIRED_FILES=(
    "$DATA_DIR/accounts_test.csv"
    "$DATA_DIR/quotes_test.csv" 
    "$MODEL_DIR/xgboost_model.joblib"
)

for file in "${REQUIRED_FILES[@]}"; do
    if [ ! -f "$file" ]; then
        echo "‚ùå Archivo faltante: $file"
        exit 1
    else
        echo "‚úÖ $file"
    fi
done

echo ""
echo "üîÑ Ejecutando pipeline paso a paso..."

# Paso 1: Preprocessing
echo "1Ô∏è‚É£ Ejecutando preprocessing..."
poetry run python src/preprocessing_data.py --config src/config/config_preprocess.yaml --dataset test
if [ $? -eq 0 ]; then
    echo "‚úÖ Preprocessing completado"
else
    echo "‚ùå Error en preprocessing"
    exit 1
fi

# Paso 2: Wrangling/Feature Engineering
echo "2Ô∏è‚É£ Ejecutando wrangling (feature engineering)..."
poetry run python src/wrangling.py --config src/config/config_wrangling.yaml --dataset test
if [ $? -eq 0 ]; then
    echo "‚úÖ Wrangling completado"
else
    echo "‚ùå Error en wrangling"
    exit 1
fi

# Paso 3: Predicci√≥n
echo "3Ô∏è‚É£ Ejecutando predicci√≥n..."
poetry run python src/detect.py --model-path model/xgboost_model.joblib --features-file features_test.csv --output-file predictions.csv
if [ $? -eq 0 ]; then
    echo "‚úÖ Predicci√≥n completada"
else
    echo "‚ùå Error en predicci√≥n"
    exit 1
fi

# Verificar resultados
echo ""
echo "üìä Verificando resultados..."

if [ -f "$DATA_DIR/predictions.csv" ]; then
    echo "‚úÖ Archivo de predicciones generado: $DATA_DIR/predictions.csv"
    
    # Mostrar estad√≠sticas b√°sicas
    echo ""
    echo "üìà Estad√≠sticas de predicciones:"
    python3 -c "
import pandas as pd
df = pd.read_csv('$DATA_DIR/predictions.csv')
print(f'Total de predicciones: {len(df)}')
print(f'Valor m√≠nimo: \${df[\"account_value\"].min():,.2f}')
print(f'Valor m√°ximo: \${df[\"account_value\"].max():,.2f}')
print(f'Valor promedio: \${df[\"account_value\"].mean():,.2f}')
print(f'Valor mediano: \${df[\"account_value\"].median():,.2f}')
print(f'\\nPrimeras 5 predicciones:')
print(df.head())
"
else
    echo "‚ùå Archivo de predicciones no encontrado"
    exit 1
fi

echo ""
echo "üéâ Pipeline completado exitosamente!"
echo "üìÅ Archivos generados:"
echo "   - $DATA_DIR/accounts_test_processed.csv"
echo "   - $DATA_DIR/features_test.csv" 
echo "   - $DATA_DIR/predictions.csv"
echo ""
echo "üöÄ Para ejecutar con Airflow:"
echo "   1. docker-compose up -d"
echo "   2. Ir a http://localhost:8080 (admin/admin)"
echo "   3. Activar y ejecutar el DAG 'coverwallet_ml_pipeline'"
