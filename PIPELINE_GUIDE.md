# CoverWallet Pipeline Execution Guide

## ğŸš€ Pipeline ML Completo

El pipeline ejecuta 3 pasos principales:
1. **Preprocessing**: Procesa datos de accounts y quotes
2. **Wrangling**: Feature engineering y encoding categÃ³rico
3. **Detection**: Genera predicciones con el modelo XGBoost

## ğŸ“‹ Archivos Creados

### Scripts
- `src/detect.py` - Script de predicciÃ³n con el modelo
- `airflow/dags/coverwallet_ml_pipeline.py` - DAG completo para Airflow
- `test_pipeline.sh` - Script para probar el pipeline localmente

### ConfiguraciÃ³n
- `docker-compose.yml` - Actualizado con volÃºmenes para el pipeline
- `test_payload.json` - Payload de ejemplo para testing de API

## ğŸƒâ€â™‚ï¸ CÃ³mo Ejecutar

### OpciÃ³n 1: Con Airflow (Recomendado)

```bash
# 1. Iniciar servicios
docker-compose up -d --build

# 2. Acceder a Airflow
open http://localhost:8080
# Login: admin / admin

# 3. En Airflow UI:
#    - Buscar DAG: 'coverwallet_ml_pipeline'
#    - Activar el DAG (toggle switch)
#    - Clickear "Trigger DAG" para ejecutar

# 4. Monitorear progreso en la UI
# 5. Verificar resultados en data/predictions.csv
```

### OpciÃ³n 2: Localmente con Poetry

```bash
# 1. Hacer script ejecutable
chmod +x test_pipeline.sh

# 2. Ejecutar pipeline completo
./test_pipeline.sh

# O ejecutar paso a paso:
poetry run python src/preprocessing_data.py --config src/config/config_preprocess.yaml --dataset test
poetry run python src/wrangling.py --config src/config/config_wrangling.yaml --dataset test
poetry run python src/detect.py --model-path model/xgboost_model.joblib --features-file features_test.csv --output-file predictions.csv
```

### OpciÃ³n 3: Solo PredicciÃ³n (si ya tienes features_test.csv)

```bash
poetry run python src/detect.py \
  --model-path model/xgboost_model.joblib \
  --features-file features_test.csv \
  --output-file predictions.csv
```

## ğŸ“Š Flujo del Pipeline

```mermaid
graph TD
    A[accounts_test.csv] --> D[Preprocessing]
    B[quotes_test.csv] --> D
    D --> E[accounts_test_processed.csv]
    E --> F[Wrangling]
    B --> F
    F --> G[features_test.csv]
    G --> H[Detection]
    C[xgboost_model.joblib] --> H
    H --> I[predictions.csv]
```

## ğŸ¯ Tareas del DAG de Airflow

1. **start_pipeline** - Inicio del pipeline
2. **check_input_files** - Verifica archivos de entrada
3. **run_preprocessing** - Ejecuta preprocessing
4. **run_wrangling** - Ejecuta feature engineering
5. **run_prediction** - Genera predicciones
6. **validate_results** - Valida formato y contenido
7. **send_notification** - NotificaciÃ³n de finalizaciÃ³n
8. **end_pipeline** - Fin del pipeline

## ğŸ“ Archivos de Entrada Requeridos

```
data/
â”œâ”€â”€ accounts_test.csv      # Datos de cuentas de test
â”œâ”€â”€ quotes_test.csv        # Datos de quotes de test
model/
â””â”€â”€ xgboost_model.joblib   # Modelo entrenado
```

## ğŸ“ Archivos de Salida Generados

```
data/
â”œâ”€â”€ accounts_test_processed.csv  # Cuentas procesadas
â”œâ”€â”€ features_test.csv           # Features finales para predicciÃ³n
â””â”€â”€ predictions.csv             # Predicciones finales (account_uuid, account_value)
```

## ğŸ”§ ConfiguraciÃ³n de VolÃºmenes Docker

El `docker-compose.yml` estÃ¡ configurado para montar:

**Airflow**:
- `./airflow/dags` â†’ `/opt/airflow/dags`
- `./model` â†’ `/opt/airflow/model`
- `./data` â†’ `/opt/airflow/data`
- `./src` â†’ `/opt/airflow/src`

**FastAPI**:
- `./model` â†’ `/model`
- `./data` â†’ `/app/data`

## ğŸ› Troubleshooting

### Error: "No module named 'src'"
```bash
# En Airflow container
export PYTHONPATH=/opt/airflow/src
```

### Error: "Model file not found"
```bash
# Verificar que el modelo existe
ls -la model/xgboost_model.joblib
```

### Error: "Features file not found"
```bash
# Ejecutar pasos previos del pipeline
poetry run python src/preprocessing_data.py --config src/config/config_preprocess.yaml --dataset test
poetry run python src/wrangling.py --config src/config/config_wrangling.yaml --dataset test
```

### Reiniciar Airflow
```bash
docker-compose restart airflow
# O completamente
docker-compose down && docker-compose up -d --build
```

## ğŸ“ˆ Monitoreo

### Logs de Airflow
```bash
docker-compose logs airflow
```

### Logs en tiempo real
```bash
docker-compose logs -f airflow
```

### Estado de tareas en Airflow UI
- Graph View: Vista grÃ¡fica del DAG
- Tree View: Vista temporal de ejecuciones
- Log View: Logs detallados de cada tarea

## âœ… ValidaciÃ³n de Resultados

El script `detect.py` valida automÃ¡ticamente:
- âœ… Todas las 37 features estÃ¡n presentes
- âœ… No hay valores nulos o infinitos
- âœ… Las predicciones son valores positivos
- âœ… El formato de salida es correcto (account_uuid, account_value)

## ğŸ‰ Resultado Final

El archivo `data/predictions.csv` contiene:
```csv
account_uuid,account_value
7c7089b9-30cc6-c5fc-9f5c8-1e4ce6a8c3,1250.75
bf68dd36-7dc94-0f5d-ebad4-19c0cdcdc7,850.25
...
```

Â¡Pipeline listo para el challenge de CoverWallet! ğŸš€
